# 1. 背景

随着互联网中数据量的不断增加，以及大数据、云计算、人工智能等新兴技术的发展，数据成为众多公司竞相追逐的目标，而高效地海量数据抓取作为数据分析的前提也受到了相关领域的关注。搜索引擎技术虽然已有很大的进步，能够满足正常用户的需求，但对于一些特殊数据搜索或复杂搜索的需求，搜索引擎的数据已经不能满足。网络安全，产品调研等问题都需要数据支持，而这些数据无法直接获取，需要手动去搜索、分析、提炼，格式化为满足需求的数据，而利用网络爬虫能够自动完成数据获取，汇总的工作，大大提升了工作效率。 在当前新的环境下，对网络爬虫的要求也不断提高，甚至需要对网络爬虫的框架以及爬取策略做出调整，以满足不断发展的行业需求。此外，网络爬虫声名远播的同时，也提高了业内对数据保护和反爬技术的关注，国内外各大网站纷纷采取了相应的反爬虫技术，增加了爬取数据的难度，对网络爬虫提出了新的挑战。

网络爬虫是一个自动获取网页的程序，它能够从互联网上下载指定 URL 的网页，是搜索引擎的重要组成。在功能上，通用的网络爬虫一般分为数据采集，处理，储存三个部分。爬虫的工作原理是：从一个或者多个初始 URL 开始，下载网页内容，然后通过搜索或是内容匹配手段（比如正则表达式），获取网页中感兴趣的内容，同时不断从当前页面提取新的 URL，根据网页抓取策略，按一定的顺序放入待抓取 URL 队列中，整个过程循环执行，一直到满足系统相应的停止条件，然后对这些被抓取的数据进行清洗，整理，并建立索引，存入数据库或文件中，最后根据查询需要，从数据库或文件中提取相应的数据，以文本或图表的方式显示出来。

目前网络爬虫技术面临的问题在于数据异构性和反爬虫机制。前者是由于不同网站的结构具有差异，甚至同一目标数据分布在不同的页面中。这些问题要求网络爬虫能够提供面向不同网站结构的，具有针对性的解析策略。反爬虫机制作为网站的一种安全防护措施，同样阻拦着网络爬虫的数据采集。反爬虫机制通常可以分为：IP封锁、验证码和登录验证三种方式。其中验证码作为最主要的反爬虫机制在近几年发生了较大的改变。从最简单的图像验证码，到弹窗验证码和滑块验证码，验证码的改变不断地促使着网络爬虫技术的更新。

基于上述问题的考虑，我们设计并实现了分布式爬虫系统，能够对新浪微博、亚马逊、淘宝、京东多个网站的分布式抓取。其中，针对这几家网站不同的反爬虫机制和不同的网页结构，本系统提供了相应的方法策略，并提供详细的代码实现。


# 2. 目的

- 互联网是企业进行发布信息的渠道，是个人共享和获取信息的工具，同时也为政府提供大量有价值的信息，用于监管企业和个人。通过互联网例如新闻博客类信息的抓取，能够发现舆论倾向，建立征信体系，发现犯罪行为等。
- 电商网站是个体户及企业进行网上销售的平台。电商网站中的数据有重要的价值，通过抓取电商网站数据，能够体现经济发展趋势，居民消费水平等。同时，可以为后续的个性化推荐提供数据支持。

# 3. 相关技术
## 3.1 Selenium(浏览器自动化测试框架)

Selenium是一个用于Web应用程序测试的工具。Selenium测试直接运行在浏览器中，就像真正的用户在操作一样。支持的浏览器包括IE（7, 8, 9, 10, 11），Mozilla Firefox，Safari，Google Chrome，Opera等。这个工具的主要功能包括：测试与浏览器的兼容性——测试你的应用程序看是否能够很好得工作在不同浏览器和操作系统之上。测试系统功能——创建回归测试检验软件功能和用户需求。支持自动录制动作和自动生成 .Net、Java、Perl等不同语言的测试脚本。

**功能：**
- 框架底层使用JavaScript模拟真实用户对浏览器进行操作。测试脚本执行时，浏览器自动按照脚本代码做出点击，输入，打开，验证等操作，就像真实用户所做的一样，从终端用户的角度测试应用程序。
- 使浏览器兼容性测试自动化成为可能，尽管在不同的浏览器上依然有细微的差别。
- 使用简单，可使用Java，Python等多种语言编写用例脚本。

**优势：**
- Selenium测试直接在浏览器中运行，就像真实用户所做的一样。Selenium 测试可以在 Windows、Linux 和 Macintosh上的 Internet Explorer、Mozilla 和 Firefox 中运行。其他测试工具都不能覆盖如此多的平台。使用 Selenium 和在浏览器中运行测试还有很多其他好处。
- Selenium模块让Python直接控制浏览器，实际点击链接，填写登录信息，几乎就像是有一个人类用户在与页面交互。与Request和Beautiful Soup相比，Selenium允许你用高级得多的方式与网页交互。附录A有安装第三方模块的详细步骤。

导入Selenium的模块需要一点技巧。不是import Selenium，而是要运行可以用Selenium启动FireFox浏览器。之后，可以用selenium启动FireFox浏览器。在交互式环境中输入以下代码：
```
1.	>>>from selenium import webdriver 
2.	>>>brower = webdriver.Firefox() 
3.	>>>type(brower) 
4.	<class 'selenium.webdriver.firefox.webdriver.WebDriver'> 
5.	>>>brower.get('http://www.amazon.com')
```

你会注意到，当webdriver.Firefox()被调用时，FireFox浏览器启动了。对值webdriver.Firefox()调用type()，揭示它具有WebDriver数据类型。调用brower.get(‘http://www.amazon.com’)将浏览器指向[Amazon](http://www.amazon.com)。浏览器应该看起来如下图所示：

![图 命令行中调用webdriver.Firfox()和get()后，Firefox浏览器出现了](http://i1.buimg.com/1949/5de8ffd686896e19.png)

## 3.2 PhantomJS
### (1) 简介

PhantomJS是一个基于webkit的JavaScript API。它使用QtWebKit作为它核心浏览器的功能，使用webkit来编译解释执行JavaScript代码。任何你可以在基于webkit浏览器 做的事情，它都能做到。它不仅是个隐形的浏览器，提供了诸如CSS选择器、支持Web标准、DOM操作、JSON、HTML5、Canvas、SVG等， 同时也提供了处理文件I/O的操作，从而使你可以向操作系统读写文件等。PhantomJS的用处可谓非常广泛，诸如前端无界面自动化测试（需要结合 Jasmin）、网络监测、网页截屏等。

### (2) PhantomJS安装

- ubuntu下面可以直接使用命令安装：
```
1.	>>>sudo apt-get install phantomjs
```

- 在终端执行phantomjs命令，如果跟下图的结果一样就表示安装成功了。
```
1.	javen@javen-virtual-machine:~$ phantomjs 
2.	phantomjs>
```

### (3) 测试
命令行中输入以下代码，即可使用phantomjs抓取界面，测试结果如图所示：
```
1.	from selenium import webdriver 
2.	driver = webdriver.PhantomJS() 
3.	driver.get("http://www.taobao.com/") 
4.	data = driver.title 
5.	print data
```
![图 phantomjs测试结果](http://i1.buimg.com/1949/64116be6687a517c.png)









